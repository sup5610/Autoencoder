{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730e049c-064d-415a-b3ca-6d72c54ac9df",
   "metadata": {},
   "source": [
    "# Autoencoder Development\n",
    "\n",
    "#### 1. Dependencies\n",
    "\n",
    "This section could include:\n",
    "* Library imports.\n",
    "* Constant definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4048adb1-c81f-49b2-8eba-93c03ba0428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53d6fc3a-afe7-47f1-a08b-e5874d6ee900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect if CUDA is available, if not use CPU\n",
    "gpu_available = torch.cuda.is_available()\n",
    "\n",
    "if gpu_available:\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# Declare global constants\n",
    "PAD_TOP = 5\n",
    "PAD_BOTTOM = 5\n",
    "PAD_LEFT = 3\n",
    "PAD_RIGHT = 4\n",
    "P_HEIGHT = 150 + PAD_TOP + PAD_BOTTOM\n",
    "P_WIDTH = 225 + PAD_LEFT + PAD_RIGHT\n",
    "\n",
    "FIRST = 16\n",
    "SECOND = 32\n",
    "THIRD = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c90b89a-efd7-4e21-9e82-860133c6384b",
   "metadata": {},
   "source": [
    "#### 2. Data Loading & Feature Engineering\n",
    "\n",
    "This section could include:\n",
    "\n",
    "* Loading of data files\n",
    "* Data manipulation\n",
    "* Feature engineering strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9acc3371-4417-4c2a-8c7e-8e870a69b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "images1 = np.load(\"subset_1.npy\")\n",
    "images2 = np.load(\"subset_2.npy\")\n",
    "images3 = np.load(\"subset_3.npy\")\n",
    "\n",
    "images = np.array(list(images1) + list(images2) + list(images3))\n",
    "\n",
    "# add padding\n",
    "def pad(images):\n",
    "    padded_images = []\n",
    "    for i in range(len(images)):\n",
    "        img = np.reshape(images[i], (150, 225, 3))\n",
    "        padded = cv2.copyMakeBorder(img, PAD_TOP, PAD_BOTTOM, PAD_LEFT, PAD_RIGHT, borderType = cv2.BORDER_CONSTANT, value = [0, 0, 0])\n",
    "        padded_images.append(padded)\n",
    "\n",
    "    images = np.array(padded_images)\n",
    "    return images\n",
    "\n",
    "images = pad(images)\n",
    "\n",
    "# split into training and testing datasets & prepare for use by neural networks\n",
    "num_images = images.shape[0]\n",
    "training_samples = int((0.75 * num_images) // 1)\n",
    "\n",
    "images = images.reshape(-1, 3, P_HEIGHT, P_WIDTH)\n",
    "np.random.shuffle(images)\n",
    "\n",
    "train_data = images[:training_samples] / 255.\n",
    "test_data = images[training_samples:] / 255.\n",
    "\n",
    "train_data = torch.tensor(train_data, dtype = torch.float32)\n",
    "test_data = torch.tensor(test_data, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53279602-f9bc-4d3f-b8ed-6d40d841bc71",
   "metadata": {},
   "source": [
    "#### 3. Model Development\n",
    "\n",
    "This section could include:\n",
    "\n",
    "* Model Definitions\n",
    "* Hyperparameter Tuning\n",
    "* Training code\n",
    "* Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ca101ff-e631-4663-93cd-73fba13748b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handles creation of encoder and decoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoder, *network_parameters):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        if network_parameters:\n",
    "            self.network_parameters = network_parameters[0]\n",
    "        else:\n",
    "            self.network_parameters = None\n",
    "\n",
    "        # If network parameters are provided, use them to create the model\n",
    "        if self.encoder:\n",
    "            self.encode = self.create_model()\n",
    "            if self.network_parameters and len(self.network_parameters) == 2:\n",
    "                try:\n",
    "                    self.encode.load_state_dict(torch.load(self.network_parameters[0], map_location = DEVICE))\n",
    "                    self.encode.to(DEVICE)\n",
    "                    self.trained = True\n",
    "                    print(\"Parameters\", self.network_parameters[0], \"loaded successfully\")\n",
    "                except Exception as err:\n",
    "                    print(\"Error loading model\")\n",
    "                    print(err)\n",
    "                    print(\"Creating new model\")\n",
    "                    self.encode.to(DEVICE)\n",
    "                    self.trained = False\n",
    "            else:\n",
    "                self.encode.to(DEVICE)\n",
    "                self.trained = False\n",
    "                \n",
    "        else:\n",
    "            self.decode = self.create_model()\n",
    "            if self.network_parameters and len(self.network_parameters) == 2:\n",
    "                try:\n",
    "                    self.decode.load_state_dict(torch.load(self.network_parameters[1], map_location = DEVICE))\n",
    "                    self.decode.to(DEVICE)\n",
    "                    self.trained = True\n",
    "                    print(\"Parameters\", self.network_parameters[1], \"loaded successfully\")\n",
    "                except Exception as err:\n",
    "                    print(\"Error loading model\")\n",
    "                    print(err)\n",
    "                    print(\"Creating new model\")\n",
    "                    self.decode.to(DEVICE)\n",
    "                    self.trained = False\n",
    "            else:\n",
    "                self.decode.to(DEVICE)\n",
    "                self.trained = False\n",
    "\n",
    "    \n",
    "    def create_model(self):\n",
    "        if self.encoder:\n",
    "            model = nn.Sequential(\n",
    "                nn.Conv2d(in_channels = 3, out_channels = FIRST, kernel_size = 2, stride = 2, padding = 0),\n",
    "                nn.LeakyReLU(0.01),\n",
    "\n",
    "                nn.Conv2d(in_channels = FIRST, out_channels = SECOND, kernel_size = 2, stride = 2, padding = 0),\n",
    "                nn.LeakyReLU(0.01),\n",
    "\n",
    "                nn.Conv2d(in_channels = SECOND, out_channels = THIRD, kernel_size = 2, stride = 2, padding = 0),\n",
    "            )\n",
    "        else:\n",
    "            model = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels = THIRD, out_channels = SECOND, kernel_size = 2, stride = 2, padding = 0),\n",
    "                nn.LeakyReLU(0.01),\n",
    "\n",
    "                nn.ConvTranspose2d(in_channels = SECOND, out_channels = FIRST, kernel_size = 2, stride = 2, padding = 0),\n",
    "                nn.LeakyReLU(0.01),\n",
    "\n",
    "                nn.ConvTranspose2d(in_channels = FIRST, out_channels = 3, kernel_size = 2, stride = 2, padding = 0),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "    # encode and decode methods, used by neural networks\n",
    "    def enc(self, x):\n",
    "        return self.encode(x)\n",
    "    \n",
    "    def dec(self, x):\n",
    "        return self.decode(x)\n",
    "    \n",
    "\n",
    "    # encode and decode methods, used for application by user\n",
    "    # takes an image as a numpy array (101250, ) and returns compressed data in a numpy array\n",
    "    def encode_data(self, image):\n",
    "        if self.trained:\n",
    "            if not self.encoder:\n",
    "                print(\"Decoder cannot encode image\")\n",
    "                return None\n",
    "            else:\n",
    "                try:\n",
    "                    original_size = image.nbytes\n",
    "                    print(\"Original image size:\", original_size / 1e6, \"MB\")\n",
    "                    image = np.reshape(image, (150, 225, 3)) / 255.\n",
    "                    image_data = cv2.copyMakeBorder(image, PAD_TOP, PAD_BOTTOM, PAD_LEFT, PAD_RIGHT, borderType = cv2.BORDER_CONSTANT, value = [0, 0, 0])\n",
    "                    image_data = image_data.reshape(3, P_HEIGHT, P_WIDTH)\n",
    "                    data = torch.tensor(image_data, dtype = torch.float32)\n",
    "                    data = data.to(DEVICE)\n",
    "                    output = self.enc(data)\n",
    "                    output = output.cpu().detach().numpy().astype(np.float16)\n",
    "                    print(\"Compressed image size:\", output.nbytes / 1e6, \"MB\")\n",
    "                    print(\"Compression ratio:\", round(original_size / output.nbytes, 5))\n",
    "\n",
    "                    return output\n",
    "                except Exception as err:\n",
    "                    print(\"Image is not in the correct format\")\n",
    "                    print(err)\n",
    "                    return None\n",
    "        else:\n",
    "            print(\"Encoder has not been trained yet\")\n",
    "            return None\n",
    "\n",
    "    # takes compressed data in a numpy array and returns it as an image in a numpy array (3, 152, 228)\n",
    "    def decode_data(self, data):\n",
    "        if self.trained:\n",
    "            if self.encoder:\n",
    "                print(\"Decoder cannot decode data\")\n",
    "                return None\n",
    "            else:\n",
    "                try:\n",
    "                    data = torch.tensor(data, dtype = torch.float32)\n",
    "                    data = data.to(DEVICE)\n",
    "                    output = self.dec(data)\n",
    "                    output = output.cpu().detach().numpy()\n",
    "                    output_image = (output * 255).astype(np.uint8)\n",
    "                    output_image = np.reshape(output_image, (P_HEIGHT, P_WIDTH, 3))\n",
    "                    clipped_image = output_image[PAD_TOP:PAD_TOP + 150, PAD_LEFT:PAD_LEFT + 225]\n",
    "\n",
    "                    return clipped_image\n",
    "                except Exception as err:\n",
    "                    print(\"Data is not in the correct format\")\n",
    "                    print(err)\n",
    "                    return None\n",
    "        else:\n",
    "            print(\"Decoder has not been trained yet\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51103a84-3a71-4094-9e81-359c98e3ba97",
   "metadata": {},
   "source": [
    "#### 4. Model Evaluation\n",
    "\n",
    "This section could include:\n",
    "\n",
    "* Testing of models trained\n",
    "* Generation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3546b86b-6bb0-4909-afd8-02f1ae98032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handels autoencoder training\n",
    "class AutoencoderTrainer:\n",
    "    def __init__(self, encoder, decoder, learning_rate, loss_f):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss_f = loss_f\n",
    "        self.optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr = self.learning_rate)\n",
    "\n",
    "    def autoencode(self, encoder, decoder, data):\n",
    "        return decoder.dec(encoder.enc(data))\n",
    "\n",
    "    # calculate loss using selected loss function\n",
    "    def calculate_loss(self, output, target):\n",
    "        loss = self.loss_f(output, target)\n",
    "        return loss\n",
    "    \n",
    "    # reset, calculate and update gradients\n",
    "    def update(self, loss):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    # train method\n",
    "    def train(self, epochs):\n",
    "        if self.encoder.trained or self.decoder.trained:\n",
    "            print(\"Encoder and/or decoder have already been trained\")\n",
    "            print(\"Create a new encoder and decoder instance to train\")\n",
    "            return None\n",
    "        else:\n",
    "            self.losses = []\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                for sample in train_data:\n",
    "                    sample = sample.to(DEVICE)\n",
    "                    output = self.autoencode(self.encoder, self.decoder, sample)  \n",
    "                    \n",
    "                    loss = self.calculate_loss(output, sample)\n",
    "                    self.update(loss)\n",
    "\n",
    "                print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "                self.losses.append(loss.item())\n",
    "\n",
    "            self.encoder.trained = True\n",
    "            self.decoder.trained = True\n",
    "\n",
    "    def test(self):\n",
    "        if self.encoder.trained and self.decoder.trained:\n",
    "            outputs = []\n",
    "            for sample in test_data:\n",
    "                sample = sample.to(DEVICE)\n",
    "                output = self.autoencode(self.encoder, self.decoder, sample)\n",
    "                outputs.append(output)\n",
    "\n",
    "            return outputs\n",
    "        else:\n",
    "            print(\"Encoder and/or decoder have not been trained yet\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f170bbbe-caa3-411f-817a-3c3408a4f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fresh encoder and decoder instances\n",
    "# encoder = Autoencoder(True)\n",
    "# decoder = Autoencoder(False)\n",
    "\n",
    "# uncomment to load pre-trained model\n",
    "network_parameters = [\"encoder_parameters.pth\", \"decoder_parameters.pth\"]\n",
    "encoder = Autoencoder(True, network_parameters)\n",
    "decoder = Autoencoder(False, network_parameters)\n",
    "\n",
    "# Train autoencoder and decoder\n",
    "lr = 0.001 # 0.0001\n",
    "epochs = 10 # 600\n",
    "loss_f = nn.MSELoss()\n",
    "trainer = AutoencoderTrainer(encoder, decoder, lr, loss_f)\n",
    "trainer.train(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858565ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network structure\n",
    "print(encoder)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b096648-b91c-43c2-9dae-a6e95bf72dd1",
   "metadata": {},
   "source": [
    "#### 5. Figure Creation\n",
    "\n",
    "This section could include:\n",
    "\n",
    "* Creation of figures for the report.\n",
    "* Creationg of tables for the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual application from user compress and unpack image\n",
    "images1 = np.load(\"subset_1.npy\")\n",
    "images2 = np.load(\"subset_2.npy\")\n",
    "images3 = np.load(\"subset_3.npy\")\n",
    "\n",
    "images = np.array(list(images1) + list(images2) + list(images3))\n",
    "\n",
    "\n",
    "i = np.random.randint(0, len(images))\n",
    "img = images[i]\n",
    "\n",
    "# encode_data takes an image as a numpy array (101250, ) and returns compressed data in a numpy array\n",
    "# decode_data takes compressed data in as a numpy array and returns it\n",
    "# as a numpy array (160, 232, 3) ready for plt.show()\n",
    "encoded = encoder.encode_data(img)\n",
    "decoded = decoder.decode_data(encoded)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f56ce-b8dc-48a2-9486-f9c180c0d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process entire test_dataset through autoencoder\n",
    "imgs = trainer.test()\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    imgs[i] = (imgs[i].detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "    imgs[i] = np.reshape(imgs[i].flatten(), (P_HEIGHT, P_WIDTH, 3))\n",
    "    imgs[i] = imgs[i][PAD_TOP:PAD_TOP + 150, PAD_LEFT:PAD_LEFT + 225]\n",
    "\n",
    "print(\"number of test images:\", len(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9e130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a random original image followed by the autoencoded version (1 second delay) for 5 images in test_data\n",
    "image_indexes = []\n",
    "for i in range(5):\n",
    "    num = np.random.randint(0, len(test_data) - 1)\n",
    "    image_indexes.append(num)\n",
    "    clear_output(wait = True)\n",
    "    test_image = np.reshape((test_data[num].numpy() * 255).astype(np.uint8), (P_HEIGHT, P_WIDTH, 3))\n",
    "    original_test_image = test_image[PAD_TOP:PAD_TOP + 150, PAD_LEFT:PAD_LEFT + 225]\n",
    "    plt.imshow(original_test_image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    time.sleep(1)\n",
    "    clear_output(wait = True)\n",
    "    plt.imshow(imgs[num])\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    time.sleep(1)\n",
    "print(image_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75da84bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare a specific image vs autoencoded image from the test dataset\n",
    "IMAGE_NUMBER = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b62fd8-9523-4a1e-8496-aa2b720536a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis(\"off\")\n",
    "compare_original = np.reshape((test_data[IMAGE_NUMBER].numpy() * 255).astype(np.uint8), (P_HEIGHT, P_WIDTH, 3))\n",
    "compare_original = compare_original[PAD_TOP:PAD_TOP + 150, PAD_LEFT:PAD_LEFT + 225]\n",
    "plt.imshow(compare_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf05393",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis(\"off\")\n",
    "compare_autoencoded = imgs[IMAGE_NUMBER]\n",
    "compare_autoencoded = compare_autoencoded[PAD_TOP:PAD_TOP + 150, PAD_LEFT:PAD_LEFT + 225]\n",
    "plt.imshow(compare_autoencoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c5db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare performance of bce vs mse\n",
    "bce_encoder = Autoencoder(True)\n",
    "bce_decoder = Autoencoder(False)\n",
    "\n",
    "mse_encoder = Autoencoder(True)\n",
    "mse_decoder = Autoencoder(False)\n",
    "\n",
    "lr = 0.001\n",
    "bce_trainer = AutoencoderTrainer(bce_encoder, bce_decoder, lr, nn.BCELoss())\n",
    "mse_trainer = AutoencoderTrainer(mse_encoder, mse_decoder, lr, nn.MSELoss())\n",
    "\n",
    "epochs = 15 # 90\n",
    "bce_trainer.train(epochs)\n",
    "mse_trainer.train(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d1932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare bce vs mse\n",
    "bce_outputs = bce_trainer.test()\n",
    "mse_outputs = mse_trainer.test()\n",
    "\n",
    "for b in range(len(bce_outputs)):\n",
    "    bce_outputs[b] = (bce_outputs[b].detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "    bce_outputs[b] = np.reshape(bce_outputs[b].flatten(), (P_HEIGHT, P_WIDTH, 3))\n",
    "\n",
    "for m in range(len(mse_outputs)):\n",
    "    mse_outputs[m] = (mse_outputs[m].detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "    mse_outputs[m] = np.reshape(mse_outputs[m].flatten(), (P_HEIGHT, P_WIDTH, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175cd7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e1510",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original image\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(test_data[num].cpu().detach().numpy().reshape(P_HEIGHT, P_WIDTH, 3)[PAD_TOP:PAD_TOP + 150, PAD_LEFT:PAD_LEFT + 225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a14f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BCE Loss\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(bce_outputs[num][PAD_TOP:PAD_TOP + 150, PAD_LEFT:PAD_LEFT + 225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8d3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSELoss\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(mse_outputs[num][PAD_TOP:PAD_TOP + 150, PAD_LEFT:PAD_LEFT + 225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa833e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model parameters\n",
    "def save_parameters(encoder_parameter_file_name, decoder_parameter_file_name):\n",
    "    encoder_parameters = torch.save(encoder.encode.state_dict(), encoder_parameter_file_name)\n",
    "    decoder_parameters = torch.save(decoder.decode.state_dict(), decoder_parameter_file_name)\n",
    "\n",
    "# save_parameters(\"new_encoder_parameters.pth\", \"new_decoder_parameters.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c519cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: lr = 0.0001, epochs = 600\n",
    "# Autoencoder(\n",
    "#   (encode): Sequential(\n",
    "#     (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(2, 2))\n",
    "#     (1): LeakyReLU(negative_slope=0.01)\n",
    "#     (2): Conv2d(16, 32, kernel_size=(2, 2), stride=(2, 2))\n",
    "#     (3): LeakyReLU(negative_slope=0.01)\n",
    "#     (4): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
    "#   )\n",
    "# )\n",
    "# Autoencoder(\n",
    "#   (decode): Sequential(\n",
    "#     (0): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
    "#     (1): LeakyReLU(negative_slope=0.01)\n",
    "#     (2): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
    "#     (3): LeakyReLU(negative_slope=0.01)\n",
    "#     (4): ConvTranspose2d(16, 3, kernel_size=(2, 2), stride=(2, 2))\n",
    "#     (5): Sigmoid()\n",
    "#   )\n",
    "# )\n",
    "\n",
    "# encoder_parameters = torch.save(encoder.encode.state_dict(), \"encoder_parameters.pth\")\n",
    "# decoder_parameters = torch.save(decoder.decode.state_dict(), \"decoder_parameters.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "# Autoencoder(\n",
    "#   (encode): Sequential(\n",
    "#     (0): Conv2d(3, 8, kernel_size=(2, 2), stride=(2, 2))\n",
    "#     (1): LeakyReLU(negative_slope=0.01)\n",
    "#     (2): Conv2d(8, 16, kernel_size=(2, 2), stride=(2, 2))\n",
    "#   )\n",
    "# )\n",
    "# Autoencoder(\n",
    "#   (decode): Sequential(\n",
    "#     (0): ConvTranspose2d(16, 8, kernel_size=(2, 2), stride=(2, 2))\n",
    "#     (1): LeakyReLU(negative_slope=0.01)\n",
    "#     (2): ConvTranspose2d(8, 3, kernel_size=(2, 2), stride=(2, 2))\n",
    "#     (3): Sigmoid()\n",
    "#   )\n",
    "# )\n",
    "\n",
    "# encoder_parameters = torch.save(encoder.encode.state_dict(), \"encoder_parameters_overfitted.pth\")\n",
    "# decoder_parameters = torch.save(decoder.decode.state_dict(), \"decoder_parameters_overfitted.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710057d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: lr = 0.0001, epochs = 800\n",
    "# Autoencoder(\n",
    "#   (encode): Sequential(\n",
    "#     (0): Conv2d(3, 8, kernel_size=(2, 2), stride=(2, 2))\n",
    "#     (1): LeakyReLU(negative_slope=0.01)\n",
    "#     (2): Conv2d(8, 24, kernel_size=(2, 2), stride=(2, 2))\n",
    "#     (3): LeakyReLU(negative_slope=0.01)\n",
    "#     (4): Conv2d(24, 48, kernel_size=(2, 2), stride=(2, 2))\n",
    "#   )\n",
    "# )\n",
    "# Autoencoder(\n",
    "#   (decode): Sequential(\n",
    "#     (0): ConvTranspose2d(48, 24, kernel_size=(2, 2), stride=(2, 2))\n",
    "#     (1): LeakyReLU(negative_slope=0.01)\n",
    "#     (2): ConvTranspose2d(24, 8, kernel_size=(2, 2), stride=(2, 2))\n",
    "#     (3): LeakyReLU(negative_slope=0.01)\n",
    "#     (4): ConvTranspose2d(8, 3, kernel_size=(2, 2), stride=(2, 2))\n",
    "#     (5): Sigmoid()\n",
    "#   )\n",
    "# )\n",
    "\n",
    "# encoder_parameters = torch.save(encoder.encode.state_dict(), \"encoder_parameters_overfitted2.pth\")\n",
    "# decoder_parameters = torch.save(decoder.decode.state_dict(), \"decoder_parameters_overfitted2.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
